# ─────────────────────────────────────────────
# Citadel-Chat: Render.com Blueprint
# ─────────────────────────────────────────────
# Deploy: Connect your GitHub repo to Render
# and it will auto-detect this file.
# ─────────────────────────────────────────────

services:
  - type: web
    name: citadel-chat
    runtime: docker
    plan: free
    dockerfilePath: ./Dockerfile
    envVars:
      - key: SECRET_KEY
        generateValue: true
      - key: PORT
        value: 8000
      - key: GROQ_API_KEY
        sync: false  # Set manually in Render dashboard
      - key: GROQ_MODEL
        value: llama-3.3-70b-versatile
      - key: EMBEDDING_MODEL
        value: all-MiniLM-L6-v2
      - key: DATA_DIR
        value: /app/data
      # STRONGLY RECOMMENDED on Render free (512 MB RAM):
      # Local sentence-transformers + PyTorch uses ~400 MB and will OOM.
      # Set this to a free HuggingFace token to use the Inference API instead.
      # Get one free at: https://huggingface.co/settings/tokens
      - key: HUGGINGFACEHUB_API_TOKEN
        sync: false
    disk:
      name: citadel-data
      mountPath: /app/data
      sizeGB: 1
